\subsection*{Performance evaluation of ML models}
\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{figures/metric_evaluation.png}
	\caption{Performance overview of ML models for PL-based sample identification. 
		The black bars represent the standard deviations of the performance metrics.}
	\label{fig:metricComparison}
\end{figure}

The prediction performance of a ML model depends on the intended application, the classification method and the data transformation algorithm.
Therefore, we compare all ML models that are generated with different combinations of classification method and transformation algorithm.
For our evaluation, we calculate the performance metrics \textit{accuracy}, \textit{precision}, \textit{recall} and \textit{f1}.
\autoref{fig:metricComparison} gives an overview of the metrics for all generated models.
We immediately see that the learning method has the biggest influence on the model's performance.
The models generated with the SVC, NuSVC, logistic regression and the random forest method achieve values over \SI{90}{\percent} for all metrics.
On the other hand, we observe a drop by \textbf{XXX} for models generated with the naive Bayes method.

Next, we look at the influence of the transformation algorithm on the performance.
We find similar metric values for models generated with the NuSVC and the logistic regression method, while for the rest, the transformation improves the metric values by at least \SI{2}{\percent}.
Interestingly, we see a trend that linear classifiers, i.e. SVC, NuSVC and logistic regression, work better with SDCM-transformed data while non-linear classifiers, i.e. random forest work best with PCA-transformed data.
Such a finding could be relevant when the computational resources must be taken into account.

Our evalutation shows clearly that the prediction performance for most of the ML models is high.
Slight improvements can be achieved by chosing the right combination of data transformation and classifier.
Note, that further improvements may also be possible by optimising the hyperparameters bound to the classification method.
\subsection*{Classification performance of ML models}
\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{figures/confusionMatrix_validation.png}
	\caption{Confusion matrix of the validation set for individual sample
		classes and classifiers, normalized along rows.}
	\label{fig:confusionMatrix}
\end{figure}

The individual ML models may work best for certain sample types in our dataset.
\autoref{fig:confusionMatrix} presents a confusion matrix of the validation dataset for all ML models generated with metric values over \SI{90}{\percent}.
The matrices are to be read as the probability (in \%) that the sample type specified in a row is classified as the type specified in the column.
For example, if we look at the ML model generated by applying SVC on the entire spectra data, the probability that PVC is identified as a non-plastic material is \SI{29}{\percent}.

We see that without any data transformation, i.e. spectra and spetra (no batchprocessing), the prediction models confuse PVC as non-plastic samples whereas with PCA and SDCM this problem is no longer present.
Futhermore, a comparison between the PCA- and SDCM based ML models reveals no tendencies towards specific sample types.
Consequently, we see that PCA and SDCM are beneficial for the identification of plastic litter using PL spectroscopy.